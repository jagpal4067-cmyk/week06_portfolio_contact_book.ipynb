{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagpal4067-cmyk/week06_portfolio_contact_book.ipynb/blob/main/week11_worksheet_testing_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J761eT5_0L34"
      },
      "source": [
        "# Workshop Overview\n",
        "\n",
        "This worksheet guides you through practical exercises in test specification and verification. You'll practice the core skills from Modules 1-3: writing specifications, designing test strategies, and working with AI to verify code quality.\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Write clear specifications using assertions\n",
        "- Apply systematic frameworks for test design (Given/When/Then, Equivalence Partitioning)\n",
        "- Make strategic decisions about test adequacy and risk\n",
        "- Evaluate AI-generated code and tests for simplicity and correctness\n",
        "- Practice the Specify → Generate → Verify → Refine cycle\n",
        "\n",
        "**Your Role:**\n",
        "You are the **strategic architect**. AI is your implementation assistant. You decide:\n",
        "- What needs testing (and what doesn't)\n",
        "- How comprehensive tests should be\n",
        "- Whether code is simple enough\n",
        "- When to ask AI for improvements\n",
        "\n",
        "**AI-First Approach:**\n",
        "We focus on \"specify and verify\" rather than manual coding. You'll learn to clearly communicate requirements to AI, then critically evaluate results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlHgmxhv0L35"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: Understanding Assertions (20 minutes)\n",
        "\n",
        "## Exercise 1.1: Reading Assertions\n",
        "\n",
        "Examine these assertions and answer the questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acXhond20L35"
      },
      "outputs": [],
      "source": [
        "def calculate_tax(amount, rate):\n",
        "    \"\"\"Calculate tax on a purchase amount.\"\"\"\n",
        "    return amount * rate\n",
        "\n",
        "# Assertions\n",
        "assert calculate_tax(100, 0.10) == 10.0\n",
        "assert calculate_tax(50, 0.20) == 10.0\n",
        "assert calculate_tax(0, 0.10) == 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erakq_LJ0L36"
      },
      "source": [
        "**Questions:**\n",
        "1. What do these assertions tell you about what the function should do?\n",
        "2. What scenarios are being tested?\n",
        "3. What scenarios are NOT tested that probably should be?\n",
        "\n",
        "**Your answers:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdgZ5u2b0L36"
      },
      "outputs": [],
      "source": [
        "# 1. These assertions show that the function multiplies the amount by the rate\n",
        "#    to calculate the correct tax amount.\n",
        "# 2. The tests check normal values and a zero case.\n",
        "# 3. They do not test negative amounts, invalid inputs, or extreme values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfM1aNs00L36"
      },
      "source": [
        "## Exercise 1.2: Writing Your First Assertions\n",
        "\n",
        "Write assertions for this function specification:\n",
        "\n",
        "**Specification:** A function `is_even(n)` that returns `True` if a number is even, `False` if odd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOox1Zwo0L36",
        "outputId": "b6feff36-68fd-4705-cdac-db6ab4fd7007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 2 → should be True\n",
            "Testing 3 → should be False\n",
            "Testing 0 → should be True\n",
            "Testing -4 → should be True\n",
            "✅ All tests passed!\n"
          ]
        }
      ],
      "source": [
        "def is_even(n):\n",
        "    \"\"\"Return True if n is even, False if odd.\"\"\"\n",
        "    return n % 2 == 0\n",
        "\n",
        "# Write at least 4 assertions testing different scenarios:\n",
        "# Assertions to test the function\n",
        "print(\"Testing 2 → should be True\")\n",
        "assert is_even(2) == True\n",
        "\n",
        "print(\"Testing 3 → should be False\")\n",
        "assert is_even(3) == False\n",
        "\n",
        "print(\"Testing 0 → should be True\")\n",
        "assert is_even(0) == True\n",
        "\n",
        "print(\"Testing -4 → should be True\")\n",
        "assert is_even(-4) == True\n",
        "\n",
        "print(\"✅ All tests passed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "8rLbbjcV0L36"
      },
      "source": [
        "**Reflection questions:**\n",
        "- What test cases did you include?\n",
        "- Did you test negative numbers? Zero? Why or why not?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjmXNRGB0L36"
      },
      "source": [
        "# Part 2: Specification Design (30 minutes)\n",
        "\n",
        "## Exercise 2.1: From Requirements to Specifications\n",
        "\n",
        "**Requirement:** \"Create a function that determines if a year is a leap year. Leap years are divisible by 4, except for years divisible by 100 (which are not leap years), unless they're also divisible by 400 (which are leap years).\"\n",
        "\n",
        "### Step 1: Understand the Requirement\n",
        "\n",
        "Write in plain language what the function should do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8AFZ2JaX0L36",
        "outputId": "e54f97e8-0015-4894-9957-f2dc3a8b2223"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYour plain language description:\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\"\"\"\n",
        "Your plain language description:\n",
        "\n",
        "\n",
        "\"\"\"# A leap year happens every 4 years.\n",
        "# But if the year is divisible by 100, it's NOT a leap year,\n",
        "# unless it is also divisible by 400, which makes it a leap year again.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDBtTml60L37"
      },
      "source": [
        "### Step 2: Apply Systematic Test Design Framework\n",
        "\n",
        "**Framework 1: Given/When/Then Structure**\n",
        "\n",
        "This helps you think clearly about test scenarios:\n",
        "- **Given** (context): What's the starting state?\n",
        "- **When** (action): What operation happens?\n",
        "- **Then** (outcome): What should result?\n",
        "\n",
        "**Framework 2: Equivalence Partitioning**\n",
        "\n",
        "Group inputs into categories that should behave the same way:\n",
        "- What are the different \"classes\" of inputs?\n",
        "- What's a representative example from each class?\n",
        "\n",
        "**Apply to Leap Year:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ttknuYu40L37"
      },
      "outputs": [],
      "source": [
        "def is_leap_year(year):\n",
        "    \"\"\"Return True if the year is a leap year, False otherwise.\"\"\"\n",
        "    if year % 400 == 0:\n",
        "        return True\n",
        "    elif year % 100 == 0:\n",
        "        return False\n",
        "    elif year % 4 == 0:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0viFblXm0L37"
      },
      "source": [
        "**Now write as Given/When/Then:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zopHqGYY0L37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "378093b1-a0fb-4ab7-d898-e6263d8d9ef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nTest Case 1:\\nGiven: A year divisible by 400 (like 2000)\\nWhen: I check if it's a leap year\\nThen: Result should be True\\n\\nTest Case 2:\\nGiven: A year divisible by 100 but not 400 (like 1900)\\nWhen: I check if it's a leap year\\nThen: Result should be False\\n\\n[Continue for other equivalence classes...]\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\"\"\"\n",
        "Test Case 1:\n",
        "Given: A year divisible by 400 (like 2000)\n",
        "When: I check if it's a leap year\n",
        "Then: Result should be True\n",
        "\n",
        "Test Case 2:\n",
        "Given: A year divisible by 100 but not 400 (like 1900)\n",
        "When: I check if it's a leap year\n",
        "Then: Result should be False\n",
        "\n",
        "[Continue for other equivalence classes...]\n",
        "\n",
        "\"\"\"  # ✅ Test 1\n",
        "# Given the year 2024 (divisible by 4 but not by 100)\n",
        "# When we check if it’s a leap year\n",
        "# Then the result should be True\n",
        "\n",
        "# ✅ Test 2\n",
        "# Given the year 1900 (divisible by 100 but not by 400)\n",
        "# When we check if it’s a leap year\n",
        "# Then the result should be False\n",
        "\n",
        "# ✅ Test 3\n",
        "# Given the year 2000 (divisible by 400)\n",
        "# When we check if it’s a leap year\n",
        "# Then the result should be True\n",
        "\n",
        "# ✅ Test 4\n",
        "# Given the year 2023 (not divisible by 4)\n",
        "# When we check if it’s a leap year\n",
        "# Then the result should be False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8NBf1GC0L37"
      },
      "source": [
        "**Boundary Analysis:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wXyzjyGk0L37"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "At the \"boundaries\" between categories, test both sides:\n",
        "\n",
        "Boundary at 100 divisibility:\n",
        "- 1896: leap (before boundary)\n",
        "- 1900: not leap (at boundary)\n",
        "- 1904: leap (after boundary)\n",
        "\n",
        "Boundary at 400 divisibility:\n",
        "- [Your examples]\n",
        "\n",
        "\"\"\" # Boundary Analysis:\n",
        "# Test years around the boundaries of leap year logic\n",
        "assert is_leap_year(1999) == False   # before 2000\n",
        "assert is_leap_year(2000) == True    # divisible by 400\n",
        "assert is_leap_year(2001) == False   # after 2000\n",
        "assert is_leap_year(2096) == True    # divisible by 4\n",
        "assert is_leap_year(2100) == False   # divisible by 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUV8c_eY0L37"
      },
      "source": [
        "### Step 3: Evaluate Test Adequacy\n",
        "\n",
        "Before writing assertions, answer these strategic questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "03bC72e30L37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "07940dba-55bb-4861-f57f-cd16ac016422"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nTest Adequacy Check:\\n\\n1. Have I covered all equivalence classes?\\n   □ Yes  □ No  □ Not sure\\n\\n2. Have I tested boundaries between classes?\\n   □ Yes  □ No  □ Not sure\\n\\n3. What's the RISK if this function fails?\\n   Low / Medium / High\\n\\n4. Based on risk, how many tests do I need?\\n   - Low risk: One per equivalence class (minimum)\\n   - Medium risk: Add boundary tests\\n   - High risk: Add extra edge cases, stress tests\\n\\n   My decision:\\n\\n5. Am I over-testing? (Could I remove tests without losing confidence?)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "Test Adequacy Check:\n",
        "\n",
        "1. Have I covered all equivalence classes?\n",
        "   □ Yes  □ No  □ Not sure\n",
        "\n",
        "2. Have I tested boundaries between classes?\n",
        "   □ Yes  □ No  □ Not sure\n",
        "\n",
        "3. What's the RISK if this function fails?\n",
        "   Low / Medium / High\n",
        "\n",
        "4. Based on risk, how many tests do I need?\n",
        "   - Low risk: One per equivalence class (minimum)\n",
        "   - Medium risk: Add boundary tests\n",
        "   - High risk: Add extra edge cases, stress tests\n",
        "\n",
        "   My decision:\n",
        "\n",
        "5. Am I over-testing? (Could I remove tests without losing confidence?)\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y4FiTPb0L38"
      },
      "source": [
        "### Step 4: Write Executable Specifications\n",
        "\n",
        "Now convert your scenarios to assertions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbc-x9th0L38"
      },
      "outputs": [],
      "source": [
        "def is_leap_year(year):\n",
        "    \"\"\"\n",
        "    Determine if a year is a leap year.\n",
        "\n",
        "    Rules:\n",
        "    - Divisible by 4: leap year\n",
        "    - Divisible by 100: NOT a leap year\n",
        "    - Divisible by 400: leap year\n",
        "    \"\"\"\n",
        "    # You'll implement this with AI assistance later\n",
        "    pass\n",
        "\n",
        "# Write your assertions here (one per equivalence class minimum):\n",
        "# assert is_leap_year(2000) == True   # Class 1: divisible by 400\n",
        "# assert is_leap_year(1900) == False  # Class 2: divisible by 100 but not 400\n",
        "# [Add your remaining assertions...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DberKORc0L38"
      },
      "source": [
        "## Exercise 2.2: AI-Assisted Scenario Discovery\n",
        "\n",
        "**Task:** Use AI to help you think comprehensively about test scenarios.\n",
        "\n",
        "**Your prompt to AI:**\n",
        "```\n",
        "I'm testing a leap year function with these rules:\n",
        "\n",
        "- Divisible by 4: leap year\n",
        "- Divisible by 100: NOT leap year  \n",
        "- Divisible by 400: leap year\n",
        "\n",
        "What test scenarios should I consider? Include:\n",
        "- Normal cases\n",
        "- Edge cases\n",
        "- Boundary conditions\n",
        "- Any tricky scenarios I might miss\n",
        "```\n",
        "\n",
        "**Copy AI's response here:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2Q-2XDP0L38"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "AI suggested scenarios:\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwWmVpQT0L38"
      },
      "source": [
        "**Your evaluation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq_Sa4AN0L38"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Which of AI's suggestions are relevant?\n",
        "Which did you already have?\n",
        "Which are new and valuable?\n",
        "Any suggestions that don't apply?\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkMzMmNm0L38"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: The Specify → Generate → Verify Cycle (40 minutes)\n",
        "\n",
        "## Exercise 3.1: Complete Implementation Workflow\n",
        "\n",
        "You'll now complete the leap year function using the full workflow.\n",
        "\n",
        "### Step 1: Your Specifications (already done above)\n",
        "\n",
        "Review your assertions from Exercise 2.1.\n",
        "\n",
        "### Step 2: Ask AI to Implement\n",
        "\n",
        "**Your prompt to AI:**\n",
        "```\n",
        "Write a Python function is_leap_year(year) that implements these rules:\n",
        "\n",
        "- Divisible by 4: leap year\n",
        "- Divisible by 100: NOT leap year\n",
        "- Divisible by 400: leap year\n",
        "\n",
        "Make these assertions pass:\n",
        "[paste your assertions here]\n",
        "\n",
        "Use only basic Python (if statements, boolean operators).\n",
        "Keep it simple and readable.\n",
        "```\n",
        "\n",
        "**Paste AI's implementation here:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ3BDmLt0L38"
      },
      "outputs": [],
      "source": [
        "# AI's implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIfcjkiL0L38"
      },
      "source": [
        "### Step 3: Verify\n",
        "\n",
        "Run the code with your assertions. Do they all pass?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz4SWHLp0L38"
      },
      "outputs": [],
      "source": [
        "# Test the implementation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Report results:\n",
        "print(\"All tests passed!\" if all_passed else \"Some tests failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yaQ8RCr0L38"
      },
      "source": [
        "### Step 4: Evaluate Code Quality\n",
        "\n",
        "Answer these questions about AI's implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjF266Pv0L39"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "1. Is the code simple enough for a beginner to understand?\n",
        "\n",
        "2. Does it use only basic Python features?\n",
        "\n",
        "3. Is the logic clear and correct?\n",
        "\n",
        "4. Would you have solved it differently? How?\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL0Zz7Ey0L39"
      },
      "source": [
        "### Step 5: Request Simplification (if needed)\n",
        "\n",
        "If the code is too complex, ask AI to simplify:\n",
        "\n",
        "**Your prompt:**\n",
        "```\n",
        "This works but is too complex for a beginner.\n",
        "Can you rewrite it using only simple if statements?\n",
        "Make the logic as clear as possible.\n",
        "```\n",
        "\n",
        "**Simpler version (if needed):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2mH34nu0L39"
      },
      "outputs": [],
      "source": [
        "# Simplified implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CkkP0ZA0L39"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 4: Test Design Practice (40 minutes)\n",
        "\n",
        "## Exercise 4.1: Strategic Test Design with Risk Analysis\n",
        "\n",
        "**Scenario:** You need to test a password strength validator.\n",
        "\n",
        "**Requirements:**\n",
        "- Password must be at least 8 characters\n",
        "- Must contain at least one uppercase letter\n",
        "- Must contain at least one number\n",
        "- Must contain at least one special character (!@#$%^&*)\n",
        "\n",
        "### Step 1: Risk Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zh_ubH90L39"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Risk Analysis:\n",
        "\n",
        "1. What happens if this function fails?\n",
        "   - Security implications:\n",
        "   - User experience impact:\n",
        "   - Business impact:\n",
        "\n",
        "2. Risk level: □ Low  □ Medium  □ High\n",
        "\n",
        "3. Based on this risk, my testing strategy should be:\n",
        "   □ Minimal - basic happy path only\n",
        "   □ Standard - equivalence classes + boundaries\n",
        "   □ Comprehensive - all edge cases, stress tests\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny8ZygF70L39"
      },
      "source": [
        "### Step 2: Equivalence Partitioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxKvLqhx0L39"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Identify equivalence classes (categories that behave the same):\n",
        "\n",
        "VALID class (all requirements met):\n",
        "- Example:\n",
        "\n",
        "INVALID classes (each requirement violation):\n",
        "- Too short (< 8 chars): Example:\n",
        "- Missing uppercase: Example:\n",
        "- Missing number: Example:\n",
        "- Missing special char: Example:\n",
        "- Multiple violations: Example:\n",
        "\n",
        "Do I need to test EVERY invalid combination?\n",
        "Decision: Yes / No\n",
        "Reasoning:\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPATmddO0L39"
      },
      "source": [
        "### Step 3: Boundary Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnlT3Pxc0L39"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Key boundaries to test:\n",
        "\n",
        "Length boundary (8 characters):\n",
        "- 7 chars (just under):\n",
        "- 8 chars (exactly at):\n",
        "- 9 chars (just over):\n",
        "\n",
        "Other boundaries?\n",
        "- Empty string?\n",
        "- Very long password (100+ chars)?\n",
        "- Only special characters?\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx0DE6Bx0L39"
      },
      "source": [
        "### Step 4: Test Adequacy Decision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Z_zeZK0L4A"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "How many tests is enough?\n",
        "\n",
        "Minimum viable: ___ tests (one per equivalence class)\n",
        "My plan: ___ tests\n",
        "\n",
        "Why this number?\n",
        "\n",
        "\n",
        "Could I get the same confidence with fewer tests?\n",
        "\n",
        "\n",
        "What am I NOT testing, and why is that OK?\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWRg7NbI0L4A"
      },
      "source": [
        "### Step 5: Write Specifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DH7zUki0L4A"
      },
      "outputs": [],
      "source": [
        "# Based on your analysis, write focused assertions:\n",
        "\n",
        "def is_strong_password(password):\n",
        "    \"\"\"Validate password strength.\"\"\"\n",
        "    pass  # To be implemented\n",
        "\n",
        "# Valid password (meets all requirements):\n",
        "# assert is_strong_password(\"Pass123!\") == True\n",
        "\n",
        "# Invalid passwords (one per major equivalence class):\n",
        "# assert is_strong_password(\"Pass12!\") == False  # too short\n",
        "# [Add remaining high-value assertions...]\n",
        "\n",
        "# Boundary tests (if risk justifies):\n",
        "# [Add if needed based on your risk assessment]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nDp50s00L4A"
      },
      "source": [
        "## Exercise 4.2: AI Implementation and Evaluation\n",
        "\n",
        "**Step 1:** Provide your specifications to AI and ask for implementation.\n",
        "\n",
        "**Your prompt:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lmEE3jw0L4A"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Write your complete prompt to AI here:\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6RJE0-o0L4A"
      },
      "source": [
        "**Step 2:** Get AI's implementation and paste it below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcoxYmck0L4A"
      },
      "outputs": [],
      "source": [
        "# AI's implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKhQ1E-g0L4A"
      },
      "source": [
        "**Step 3:** Test it with your assertions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQmb0f1g0L4A"
      },
      "outputs": [],
      "source": [
        "# Run your assertions here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elyVkywW0L4B"
      },
      "source": [
        "**Step 4:** Critical Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkGb-Z7t0L4B"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Strategic Evaluation:\n",
        "\n",
        "1. Does it pass all your assertions?\n",
        "\n",
        "2. Code Simplicity:\n",
        "   - Can a beginner understand this?\n",
        "   - Does it use only basic Python constructs?\n",
        "   - Is there a simpler approach?\n",
        "\n",
        "3. Did you find any bugs or issues?\n",
        "\n",
        "4. Test Coverage:\n",
        "   - Are there scenarios you didn't test?\n",
        "   - Are they worth testing (risk vs. effort)?\n",
        "   - Decision: Add tests / Leave as-is\n",
        "\n",
        "5. Should you request simplification?\n",
        "   - Prompt to use: \"Make this simpler using only basic if statements\"\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRDFRvaE0L4B"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 5: Regression Testing & Bug Prevention (30 minutes)\n",
        "\n",
        "When bugs are discovered, the AI-first approach is:\n",
        "1. **Write a failing test** that captures the bug\n",
        "2. **Specify the fix** to AI clearly\n",
        "3. **Verify the fix** passes your test\n",
        "4. **Keep the test** to prevent regression\n",
        "\n",
        "## Exercise 5.1: Specification-First Bug Fixing\n",
        "\n",
        "You discover this buggy code in production:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eTUf4Bz0L4B"
      },
      "outputs": [],
      "source": [
        "def average_positive(numbers):\n",
        "    \"\"\"Calculate average of positive numbers only.\"\"\"\n",
        "    total = 0\n",
        "    count = 0\n",
        "    for num in numbers:\n",
        "        if num > 0:\n",
        "            total += num\n",
        "        count += 1\n",
        "    return total / count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3z6FPYX0L4B"
      },
      "source": [
        "**Step 1: Write a failing test that demonstrates the bug**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgVAattL0L4B"
      },
      "outputs": [],
      "source": [
        "# First, understand what SHOULD happen:\n",
        "# Input: [2, -1, 4, -3]\n",
        "# Positive numbers: [2, 4]\n",
        "# Average: (2 + 4) / 2 = 3.0\n",
        "\n",
        "# Write the assertion that currently fails:\n",
        "def average_positive(numbers):\n",
        "    \"\"\"Calculate average of positive numbers only.\"\"\"\n",
        "    total = 0\n",
        "    count = 0\n",
        "    for num in numbers:\n",
        "        if num > 0:\n",
        "            total += num\n",
        "        count += 1\n",
        "    return total / count\n",
        "\n",
        "# TODO: Write assertion here that will fail\n",
        "# assert average_positive([2, -1, 4, -3]) == ???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ih0MZtS0L4B"
      },
      "source": [
        "**Step 2: Specify the bug to AI**\n",
        "\n",
        "Write a clear bug report prompt for AI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqHfw4DV0L4B"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Your prompt to AI:\n",
        "\n",
        "The function average_positive should calculate the average of ONLY positive numbers,\n",
        "ignoring negative numbers.\n",
        "\n",
        "Current behavior:\n",
        "[describe what it does wrong]\n",
        "\n",
        "Expected behavior:\n",
        "[describe what it should do]\n",
        "\n",
        "Here are the tests that should pass:\n",
        "[paste your assertions]\n",
        "\n",
        "Please fix the function to pass these tests. Keep it simple.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iST6IL1L0L4B"
      },
      "source": [
        "**Step 3: Get AI's fix and verify**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49E451G70L4B"
      },
      "outputs": [],
      "source": [
        "# Paste AI's corrected version here:\n",
        "\n",
        "\n",
        "# Run your test assertions to verify:\n",
        "# [Your test assertions]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FbZDnBm0L4B"
      },
      "source": [
        "**Step 4: Add edge case tests**\n",
        "\n",
        "Now that the basic bug is fixed, what edge cases should you add?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5rkbMZP0L4C"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Additional scenarios to test:\n",
        "\n",
        "1. All negative numbers: [-1, -2, -3]\n",
        "   Expected behavior:\n",
        "\n",
        "2. Empty list: []\n",
        "   Expected behavior:\n",
        "\n",
        "3. Mix with zero: [0, 1, 2]\n",
        "   Expected behavior:\n",
        "\"\"\"\n",
        "\n",
        "# Write assertions for these edge cases:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXsHOMI30L4C"
      },
      "source": [
        "## Exercise 5.2: AI-Driven Bug Investigation\n",
        "\n",
        "You receive a bug report: \"find_max returns 0 for negative numbers\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsKJigur0L4C"
      },
      "outputs": [],
      "source": [
        "def find_max(numbers):\n",
        "    \"\"\"Find the maximum number in a list.\"\"\"\n",
        "    max_num = 0\n",
        "    for num in numbers:\n",
        "        if num > max_num:\n",
        "            max_num = num\n",
        "    return max_num\n",
        "\n",
        "# Works for positive:\n",
        "print(find_max([3, 1, 4, 1, 5]))  # Returns 5 ✓\n",
        "\n",
        "# Fails for all negative:\n",
        "print(find_max([-5, -2, -8, -1]))  # Returns 0 ✗ (should return -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH9fYEpP0L4C"
      },
      "source": [
        "**Step 1: Write failing test specifications**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWBqAIJ00L4C"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Test cases that should pass but currently fail:\n",
        "\n",
        "1. All negative numbers:\n",
        "   assert find_max([-5, -2, -8, -1]) == -1\n",
        "\n",
        "2. [Add another edge case test]\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRHTRG0E0L4C"
      },
      "source": [
        "**Step 2: Prompt AI to fix based on your tests**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfiWJ92G0L4C"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Your prompt to AI:\n",
        "\n",
        "This find_max function has a bug. It returns 0 for lists of all negative numbers.\n",
        "\n",
        "Make these assertions pass:\n",
        "[paste your test assertions]\n",
        "\n",
        "Explain the fix in simple terms, then provide corrected code.\n",
        "Keep the solution simple - use only basic Python.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6_98nP60L4C"
      },
      "source": [
        "**Step 3: Evaluate AI's explanation and fix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwCFmhkl0L4C"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Paste AI's explanation:\n",
        "\n",
        "\n",
        "Paste AI's fixed code:\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2IsYAkv0L4C"
      },
      "source": [
        "**Step 4: Verify and add to test suite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8c5zPHo0L4D"
      },
      "outputs": [],
      "source": [
        "# Paste the fixed function here:\n",
        "\n",
        "\n",
        "# Run all your test assertions:\n",
        "# [Your assertions]\n",
        "\n",
        "# Reflection: How does the AI-first approach compare to manual debugging?\n",
        "\"\"\"\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvFbmsAt0L4D"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 6: Integration Exercise (45 minutes)\n",
        "\n",
        "## Exercise 6.1: Complete Feature Development\n",
        "\n",
        "**Scenario:** Build a grade calculator with full testing.\n",
        "\n",
        "**Requirements:**\n",
        "- Function calculates letter grade from numeric score\n",
        "- A: 90-100, B: 80-89, C: 70-79, D: 60-69, F: below 60\n",
        "- Should handle invalid inputs gracefully\n",
        "\n",
        "### Step 1: Apply Complete Testing Framework\n",
        "\n",
        "**A. Risk Assessment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAITCAF60L4D"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Risk Analysis:\n",
        "\n",
        "1. What's the consequence if this function fails?\n",
        "\n",
        "2. Risk level: □ Low  □ Medium  □ High\n",
        "\n",
        "3. Testing approach based on risk:\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp1umB690L4D"
      },
      "source": [
        "**B. Equivalence Classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLX36g4H0L4D"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Identify input categories:\n",
        "\n",
        "Grade A (90-100): Example score:\n",
        "Grade B (80-89):  Example score:\n",
        "Grade C (70-79):  Example score:\n",
        "Grade D (60-69):  Example score:\n",
        "Grade F (<60):    Example score:\n",
        "\n",
        "Invalid inputs:   Examples:\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXk-C0xH0L4D"
      },
      "source": [
        "**C. Boundaries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn1mUMcx0L4D"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Critical boundaries (where behavior changes):\n",
        "\n",
        "89.9 vs 90.0 (B/A boundary):\n",
        "- Test 89: expect B\n",
        "- Test 90: expect A\n",
        "- Test 91: expect A\n",
        "\n",
        "[Identify other critical boundaries...]\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obmGfs_N0L4D"
      },
      "source": [
        "**D. Test Adequacy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-gSF6gP0L4D"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Minimum tests needed: ___ (one per equivalence class)\n",
        "Boundary tests needed: ___ (based on risk)\n",
        "Total planned tests: ___\n",
        "\n",
        "Justification:\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSCAGyrn0L4D"
      },
      "source": [
        "### Step 2: Write Specifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcAOIXeA0L4D"
      },
      "outputs": [],
      "source": [
        "def calculate_grade(score):\n",
        "    \"\"\"Convert numeric score to letter grade.\"\"\"\n",
        "    pass\n",
        "\n",
        "# Your assertions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk5_MxNi0L4D"
      },
      "source": [
        "### Step 3: AI Implementation\n",
        "\n",
        "**Your prompt:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n46h5kf30L4E"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Write your specification prompt to AI:\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVY9frFC0L4E"
      },
      "source": [
        "**AI's implementation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5iEf2XG0L4E"
      },
      "outputs": [],
      "source": [
        "# Paste AI's code:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsFe1YrW0L4E"
      },
      "source": [
        "### Step 4: Verify and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxIBJGIp0L4E"
      },
      "outputs": [],
      "source": [
        "# Run all your assertions\n",
        "\n",
        "\n",
        "# Strategic Evaluation:\n",
        "\"\"\"\n",
        "\n",
        "1. Do all tests pass?\n",
        "\n",
        "2. Simplicity check:\n",
        "   - Could a beginner understand this without help?\n",
        "   - If no: What prompt would simplify it?\n",
        "\n",
        "3. Test adequacy review:\n",
        "   - Given the risk level, are my tests sufficient?\n",
        "   - Am I over-testing (wasting effort on low-value tests)?\n",
        "   - Am I under-testing (missing critical scenarios)?\n",
        "\n",
        "4. What would you improve?\n",
        "   - In the code?\n",
        "   - In the tests?\n",
        "   - In your process?\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x6nvwxH0L4E"
      },
      "source": [
        "### Step 5: Add a Bug Test\n",
        "\n",
        "Add a test for a bug you discovered (or imagine discovering):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pd8qqxR0L4E"
      },
      "outputs": [],
      "source": [
        "# Test for edge case you found:\n",
        "\n",
        "\n",
        "# This test should fail initially if there was a bug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llozZ96U0L4E"
      },
      "source": [
        "---\n",
        "\n",
        "# Reflection and Synthesis (15 minutes)\n",
        "\n",
        "## Final Reflection\n",
        "\n",
        "Answer these questions about your learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iZ_8Un20L4E"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "1. Strategic Thinking:\n",
        "   What was most challenging about deciding WHAT to test (vs. HOW to test)?\n",
        "\n",
        "\n",
        "2. AI Collaboration:\n",
        "   How did your role as \"architect\" differ from traditional coding?\n",
        "   What decisions did YOU make vs. what did AI do?\n",
        "\n",
        "\n",
        "3. Test Design Frameworks:\n",
        "   Which framework was most useful (Given/When/Then, Equivalence Classes, Risk Analysis)?\n",
        "   Why?\n",
        "\n",
        "\n",
        "4. Test Adequacy:\n",
        "   How did you decide when you had \"enough\" tests?\n",
        "   What guided those decisions?\n",
        "\n",
        "\n",
        "5. AI-First Approach:\n",
        "   Will you use \"specify and verify\" in future projects?\n",
        "   What's the biggest benefit? Biggest challenge?\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqP6y7wQ0L4E"
      },
      "source": [
        "## Key Takeaways Checklist\n",
        "\n",
        "Check off what you've learned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3B1Jq1L0L4E"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Strategic Skills:\n",
        "□ I can make risk-based decisions about test coverage\n",
        "□ I can apply systematic frameworks (Given/When/Then, Equivalence Partitioning)\n",
        "□ I can evaluate test adequacy (when is \"enough\" enough?)\n",
        "□ I can identify what NOT to test and justify why\n",
        "\n",
        "AI Collaboration Skills:\n",
        "□ I can write clear specifications that AI can implement\n",
        "□ I can evaluate AI-generated code for simplicity and correctness\n",
        "□ I can prompt AI to simplify overly complex solutions\n",
        "□ I understand my role as architect (not just code consumer)\n",
        "\n",
        "Testing Skills:\n",
        "□ I can write assertions that clearly specify expected behavior\n",
        "□ I can design comprehensive test strategies using frameworks\n",
        "□ I can use AI to discover scenarios I might have missed\n",
        "□ I understand Specify → Generate → Verify → Refine cycle\n",
        "\n",
        "Quality Decisions:\n",
        "□ I know when to add more tests vs. when to stop\n",
        "□ I can balance test thoroughness with practical constraints\n",
        "□ I can specify bug fixes rather than manually debugging\n",
        "□ I can maintain strategic control while using AI assistance\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvO2E7gN0L4F"
      },
      "source": [
        "---\n",
        "\n",
        "# Extension Challenges (Optional)\n",
        "\n",
        "If you finish early or want more practice:\n",
        "\n",
        "## Challenge 1: Roman Numeral Converter\n",
        "\n",
        "Design comprehensive tests for a function that converts integers (1-3999) to Roman numerals.\n",
        "\n",
        "Research the rules, design test strategy, implement with AI assistance.\n",
        "\n",
        "## Challenge 2: Email Validator\n",
        "\n",
        "Design tests for email validation. Consider:\n",
        "- What makes a valid email?\n",
        "- What edge cases exist?\n",
        "- How should errors be handled?\n",
        "\n",
        "## Challenge 3: Shopping Cart\n",
        "\n",
        "Design tests for a shopping cart that:\n",
        "- Adds items\n",
        "- Removes items\n",
        "- Calculates totals\n",
        "- Applies discounts\n",
        "\n",
        "Think about state, multiple operations, edge cases.\n",
        "\n",
        "---\n",
        "\n",
        "# Submission Checklist\n",
        "\n",
        "Before submitting, ensure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLLGLmBz0L4F"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Technical Completion:\n",
        "□ All exercises attempted\n",
        "□ Code cells executed and tested\n",
        "□ AI prompts and responses documented\n",
        "\n",
        "Strategic Thinking Evidence:\n",
        "□ Risk assessments completed for exercises\n",
        "□ Equivalence classes identified and justified\n",
        "□ Test adequacy decisions documented with reasoning\n",
        "□ At least one example of deciding NOT to test something (with justification)\n",
        "\n",
        "AI Collaboration Evidence:\n",
        "□ Your own thinking clearly shown (not just AI output)\n",
        "□ Critical evaluations of AI code completed\n",
        "□ At least one example of requesting simplification\n",
        "□ At least one example of specifying a bug fix (not manually debugging)\n",
        "\n",
        "Reflection:\n",
        "□ Reflection questions answered thoughtfully\n",
        "□ Key takeaways checklist reviewed\n",
        "□ Understanding of strategic architect role demonstrated\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}